for (i in seq_along(thresholds)) {
th <- thresholds[i]
fit <- try(fpot(daily_maxima$value, threshold = th), silent = TRUE)
if (!inherits(fit, "try-error")) {
locs[i] <- th
scales[i] <- fit$estimate["scale"]
shapes[i] <- fit$estimate["shape"]
mean_excess[i] <- mean(daily_maxima$value[daily_maxima$value > th] - th)
} else {
locs[i] <- NA
scales[i] <- NA
shapes[i] <- NA
mean_excess[i] <- NA
}
}
par(mfrow = c(2, 2))
plot(thresholds, locs, type = "b", pch = 16, main = "Location parameter", xlab = "Threshold", ylab = "Loc")
par(mfrow = c(2, 2))
plot(thresholds, locs, type = "b", pch = 16, main = "Location parameter", xlab = "Threshold", ylab = "Loc")
plot(thresholds, scales, type = "b", pch = 16, main = "Scale parameter", xlab = "Threshold", ylab = "Scale")
plot(thresholds, shapes, type = "b", pch = 16, main = "Shape parameter", xlab = "Threshold", ylab = "Shape")
plot(thresholds, mean_excess, type = "b", pch = 16, main = "Mean excess function", xlab = "Threshold", ylab = "Mean excess")
# Fitting standard three-parameter POT to annual maxima
u<-108 # Chosen based on threshold stability plots
fit.pot_year1<-fpot(data2025$no2, threshold = u)
par(mfrow=c(1,4))
plot(fit.pot_year1)
plot(profile(fit.pot_year1))
# Number of observations per year (hourly data)
npp <- 8766  # 24 × 365.25
# Fit GPD with POT model for 10-year return period (slide 97)
fit_pot_10 <- fpot(data2025$no2, threshold = u, mper = 10, npp = npp)
plot(fit_pot_10)
# Fit GPD with POT model for 100-year return period
fit_pot_100 <- fpot(data2025$no2, threshold = u, mper = 100, npp = npp)
plot(fit_pot_100)
# Inputs
u <- 108               # Threshold
npp <- 8766            # 24 × 365.25
zeta_u <- mean(data2025$no2 > u, na.rm = TRUE)  # Proportion of exceedances
# Estimated parameters from the GPD fit
xi <- fit_pot$estimate["shape"]
# Extract parameters
xi <- fit_pot_winter$estimate["shape"]
> threshold_extreme)
# Add month information
data.tmp <- data.frame(
date = data2025$date,
value = data2025$no2,
month = lubridate::month(data2025$date, label = TRUE)
)
# Filter extreme values
extremes <- data.tmp %>% filter(value > threshold_extreme)
load("C:/Users/micae/OneDrive/Bureau/Risk and environnemental sustainability/Mini Projet/Mini-Project/Sheffield.Tinsley_no2.Rdata")
# Loading data
data2025<-Sheffield.Tinsley
# See structure of the object
head(data2025)
# Creation of a data-frame object
library(lubridate)
data.tmp <- data.frame("date"= data2025$date, "value"= data2025$no2,
"year"= year(data2025$date), "month"= month(data2025$date), "week" = isoweek(data2025$date), "day"= day(data2025$date))
# compute daily maximum of hourly measurements
library(tidyr)
library(dplyr)
daily_maxima <-data.tmp %>%
group_by(year, month, week, day) %>%
slice_max(order_by = value, n = 1, with_ties = FALSE) %>%
drop_na() #drop missing observations
# Compute monthly maximum of hourly measurements
library(dplyr)
monthly_maxima <-data.tmp %>%
group_by(year, month) %>%
slice_max(order_by = value, n = 1, with_ties = FALSE) %>%
drop_na() #drop missing observations
# Compute weekly maximum of hourly measurements
# Compute weekly maximum of hourly measurements
library(dplyr)
weekly_maxima <-data.tmp %>%
group_by(year, month, week) %>%
slice_max(order_by = value, n = 1, with_ties = FALSE) %>%
drop_na() #drop missing observations
# Compute yearly maximum of hourly measurements
library(dplyr)
yearly_maxima <-data.tmp %>%
group_by(year) %>%
slice_max(order_by = value, n = 1, with_ties = FALSE) %>%
drop_na() #drop missing observations
# Fitting standard three-parameter GEV to annual maxima
value_year<-yearly_maxima$value
fit_year1<-fgev(value_year, prob=1/10)
fit_year2<-fgev(value_year, prob=1/100)
fit_year1
fit_year2
par(mfrow=c(1,4))
plot(fit_year1)
plot(fit_year2)
par(mfrow=c(1,3))
plot(profile(fit_year1))
plot(profile(fit_year2))
# Fitting standard three-parameter GEV to monthly maxima
value_month<-monthly_maxima$value
fit_month1<-fgev(value_month, prob=1/(10*12))
fit_month2<-fgev(value_month, prob=1/(100*12))
fit_month1
fit_month2
par(mfrow=c(1,4))
plot(fit_month1)
plot(fit_month2)
plot(profile(fit_month1))
plot(profile(fit_month2))
# Choisir une séquence de seuils à tester (par ex. percentiles 85 % à 98 %)
thresholds <- quantile(daily_maxima$value, probs = seq(0.85, 0.98, by = 0.01), na.rm = TRUE)
# Initialiser des vecteurs pour stocker les estimations
locs <- scales <- shapes <- mean_excess <- numeric(length(thresholds))
# Boucle pour ajuster fpot() à chaque seuil et stocker les paramètres
for (i in seq_along(thresholds)) {
th <- thresholds[i]
fit <- try(fpot(daily_maxima$value, threshold = th), silent = TRUE)
if (!inherits(fit, "try-error")) {
locs[i] <- th
scales[i] <- fit$estimate["scale"]
shapes[i] <- fit$estimate["shape"]
mean_excess[i] <- mean(daily_maxima$value[daily_maxima$value > th] - th)
} else {
locs[i] <- NA
scales[i] <- NA
shapes[i] <- NA
mean_excess[i] <- NA
}
}
par(mfrow = c(2, 2))
plot(thresholds, locs, type = "b", pch = 16, main = "Location parameter", xlab = "Threshold", ylab = "Loc")
plot(thresholds, scales, type = "b", pch = 16, main = "Scale parameter", xlab = "Threshold", ylab = "Scale")
plot(thresholds, shapes, type = "b", pch = 16, main = "Shape parameter", xlab = "Threshold", ylab = "Shape")
plot(thresholds, mean_excess, type = "b", pch = 16, main = "Mean excess function", xlab = "Threshold", ylab = "Mean excess")
# Fitting standard three-parameter POT to annual maxima
u<-108 # Chosen based on threshold stability plots
fit.pot_year1<-fpot(data2025$no2, threshold = u)
par(mfrow=c(1,4))
plot(fit.pot_year1)
plot(profile(fit.pot_year1))
# Number of observations per year (hourly data)
npp <- 8766  # 24 × 365.25
# Fit GPD with POT model for 10-year return period (slide 97)
fit_pot_10 <- fpot(data2025$no2, threshold = u, mper = 10, npp = npp)
plot(fit_pot_10)
# Fit GPD with POT model for 100-year return period
fit_pot_100 <- fpot(data2025$no2, threshold = u, mper = 100, npp = npp)
plot(fit_pot_100)
# Inputs
u <- 108               # Threshold
npp <- 8766            # 24 × 365.25
zeta_u <- mean(data2025$no2 > u, na.rm = TRUE)  # Proportion of exceedances
# Estimated parameters from the GPD fit
xi <- fit_pot$estimate["shape"]
# Inputs
u <- 108               # Threshold
npp <- 8766            # 24 × 365.25
zeta_u <- mean(data2025$no2 > u, na.rm = TRUE)  # Proportion of exceedances
# Estimated parameters from the GPD fit
xi <- fit_pot$estimate["shape"]
fit_pot <- fpot(data2025$no2, threshold = u, std.err = TRUE)
# Estimated parameters from the GPD fit
xi <- fit_pot$estimate["shape"]
sigma <- fit_pot$estimate["scale"]
# Function to compute return level for a given T
pot_return_level <- function(T, u, sigma, xi, zeta_u) {
if (abs(xi) < 1e-6) {
# Gumbel case
return(u + sigma * log(T * zeta_u))
} else {
return(u + (sigma / xi) * ((T * zeta_u)^xi - 1))
}
}
# 10- and 100-year return levels
y10 <- pot_return_level(10, u, sigma, xi, zeta_u)
y100 <- pot_return_level(100, u, sigma, xi, zeta_u)
# Output
cat("10-year return level:", round(y10, 2), "\n")
cat("100-year return level:", round(y100, 2), "\n")
library(dplyr)
# Get top 1% of all hourly values
threshold_extreme <- quantile(data2025$no2, 0.99, na.rm = TRUE)
# Add month information
data.tmp <- data.frame(
date = data2025$date,
value = data2025$no2,
month = lubridate::month(data2025$date, label = TRUE)
)
# Filter extreme values
extremes <- data.tmp %>% filter(value > threshold_extreme)
# Plot frequency of extremes by month
barplot(table(extremes$month),
main = "Monthly frequency of top 1% NO₂ values",
ylab = "Count of extreme values",
xlab = "Month")
library(lubridate)
library(evir)
# Filter observations between November and March
data.tmp <- data.frame(date = data2025$date, value = data2025$no2)
data.tmp$month <- month(data.tmp$date)
winter_data <- data.tmp %>% filter(month %in% c(11, 12, 1, 2, 3))
# Choose a threshold (e.g. 95th percentile of winter data)
u_winter <- quantile(winter_data$value, 0.95, na.rm = TRUE)
# Fit POT model on winter data
fit_pot_winter <- fpot(winter_data$value, threshold = u_winter, std.err = TRUE)
# Estimate exceedance probability (proportion above threshold)
zeta_u <- mean(winter_data$value > u_winter, na.rm = TRUE)
# Extract parameters
xi <- fit_pot_winter$estimate["shape"]
sigma <- fit_pot_winter$estimate["scale"]
# Return level formula (slide 102)
pot_return_level <- function(T, u, sigma, xi, zeta_u) {
if (abs(xi) < 1e-6) {
return(u + sigma * log(T * zeta_u))
} else {
return(u + (sigma / xi) * ((T * zeta_u)^xi - 1))
}
}
# Compute 10- and 100-year return levels
y10 <- pot_return_level(10, u_winter, sigma, xi, zeta_u)
y100 <- pot_return_level(100, u_winter, sigma, xi, zeta_u)
# Print results
cat("Winter POT model (Nov–Mar):\n")
cat("Threshold (u):", round(u_winter, 2), "\n")
cat("10-year return level:", round(y10, 2), "\n")
cat("100-year return level:", round(y100, 2), "\n")
# Loading data
data2025<-Sheffield.Tinsley
load("C:/Users/micae/OneDrive/Bureau/Risk and environnemental sustainability/Mini Projet/Mini-Project/Sheffield.Tinsley_no2.Rdata")
# Loading data
data2025<-Sheffield.Tinsley
# See structure of the object
head(data2025)
# Creation of a data-frame object
library(lubridate)
data.tmp <- data.frame("date"= data2025$date, "value"= data2025$no2,
"year"= year(data2025$date), "month" = month(data2025$date), "week" = isoweek(data2025$date), "day"= day(data2025$date))
# compute daily maximum of hourly measurements
library(tidyr)
library(dplyr)
daily_maxima <-data.tmp %>%
group_by(year, month, week, day) %>%
slice_max(order_by = value, n = 1, with_ties = FALSE) %>%
drop_na() #drop missing observations
# Compute monthly maximum of hourly measurements
library(dplyr)
monthly_maxima <-data.tmp %>%
group_by(year, month) %>%
slice_max(order_by = value, n = 1, with_ties = FALSE) %>%
drop_na() #drop missing observations
# Compute weekly maximum of hourly measurements
library(dplyr)
weekly_maxima <-data.tmp %>%
group_by(year, month, week) %>%
slice_max(order_by = value, n = 1, with_ties = FALSE) %>%
drop_na() #drop missing observations
# Compute yearly maximum of hourly measurements
library(dplyr)
yearly_maxima <-data.tmp %>%
group_by(year) %>%
slice_max(order_by = value, n = 1, with_ties = FALSE) %>%
drop_na() #drop missing observations
# Fitting standard three-parameter GEV to annual maxima
value_year<-yearly_maxima$value
fit_year<-fgev(value_year)
fit_year1<-fgev(value_year, prob=1/10)
fit_year2<-fgev(value_year, prob=1/100)
fit_year
fit_year1
fit_year2
par(mfrow=c(1,4))
plot(fit_year)
# Loading data
data2025<-Sheffield.Tinsley
# See structure of the object
head(data2025)
# Creation of a data-frame object
library(lubridate)
data.tmp <- data.frame("date"= data2025$date, "value"= data2025$no2,
"year"= year(data2025$date), "month" = month(data2025$date), "week" = isoweek(data2025$date), "day"= day(data2025$date))
value_year<-yearly_maxima$value
fit_year<-fgev(value_year)
fit_year1<-fgev(value_year, prob=1/10)
fit_year2<-fgev(value_year, prob=1/100)
fit_year
fit_year1
fit_year2
par(mfrow=c(1,4))
plot(fit_year)
# Loading data
data2025<-Sheffield.Tinsley
# See structure of the object
head(data2025)
# Creation of a data-frame object
library(lubridate)
data.tmp <- data.frame("date"= data2025$date, "value"= data2025$no2,
"year"= year(data2025$date), "month" = month(data2025$date), "week" = isoweek(data2025$date), "day"= day(data2025$date))
# compute daily maximum of hourly measurements
library(tidyr)
library(dplyr)
daily_maxima <-data.tmp %>%
group_by(year, month, week, day) %>%
slice_max(order_by = value, n = 1, with_ties = FALSE) %>%
drop_na() #drop missing observations
# Compute monthly maximum of hourly measurements
library(dplyr)
monthly_maxima <-data.tmp %>%
group_by(year, month) %>%
slice_max(order_by = value, n = 1, with_ties = FALSE) %>%
drop_na() #drop missing observations
# Compute weekly maximum of hourly measurements
library(dplyr)
weekly_maxima <-data.tmp %>%
group_by(year, month, week) %>%
slice_max(order_by = value, n = 1, with_ties = FALSE) %>%
drop_na() #drop missing observations
# Compute yearly maximum of hourly measurements
library(dplyr)
yearly_maxima <-data.tmp %>%
group_by(year) %>%
slice_max(order_by = value, n = 1, with_ties = FALSE) %>%
drop_na() #drop missing observations
# Fitting standard three-parameter GEV to annual maxima
value_year<-yearly_maxima$value
fit_year<-fgev(value_year)
fit_year1<-fgev(value_year, prob=1/10)
fit_year2<-fgev(value_year, prob=1/100)
fit_year
fit_year1
fit_year2
par(mfrow=c(1,4))
plot(fit_year)
par(mfrow=c(1,4))
plot(fit_year)
# Loading data
data2025<-Sheffield.Tinsley
# See structure of the object
head(data2025)
# Creation of a data-frame object
library(lubridate)
data.tmp <- data.frame("date"= data2025$date, "value"= data2025$no2,
"year"= year(data2025$date), "month" = month(data2025$date), "week" = isoweek(data2025$date), "day"= day(data2025$date))
# compute daily maximum of hourly measurements
library(tidyr)
library(dplyr)
daily_maxima <-data.tmp %>%
group_by(year, month, week, day) %>%
slice_max(order_by = value, n = 1, with_ties = FALSE) %>%
drop_na() #drop missing observations
# Compute monthly maximum of hourly measurements
library(dplyr)
monthly_maxima <-data.tmp %>%
group_by(year, month) %>%
slice_max(order_by = value, n = 1, with_ties = FALSE) %>%
drop_na() #drop missing observations
# Compute weekly maximum of hourly measurements
library(dplyr)
weekly_maxima <-data.tmp %>%
group_by(year, month, week) %>%
slice_max(order_by = value, n = 1, with_ties = FALSE) %>%
drop_na() #drop missing observations
# Compute yearly maximum of hourly measurements
library(dplyr)
yearly_maxima <-data.tmp %>%
group_by(year) %>%
slice_max(order_by = value, n = 1, with_ties = FALSE) %>%
drop_na() #drop missing observations
# Fitting standard three-parameter GEV to annual maxima
value_year<-yearly_maxima$value
fit_year<-fgev(value_year)
fit_year1<-fgev(value_year, prob=1/10)
fit_year2<-fgev(value_year, prob=1/100)
fit_year
fit_year1
fit_year2
par(mfrow=c(1,4))
plot(fit_year)
# Fitting standard three-parameter GEV to annual maxima
value_year<-yearly_maxima$value
fit_year<-fgev(value_year)
fit_year1<-fgev(value_year, prob=1/10)
fit_year2<-fgev(value_year, prob=1/100)
fit_year
par(mfrow=c(1,4))
plot(fit_year)
par(mfrow=c(1,4))
plot(fit_year)
par(mfrow=c(1,4))
plot(fit_year)
plot(fit_year,which=1)
# Loading data
data2025<-Sheffield.Tinsley
# See structure of the object
head(data2025)
# Creation of a data-frame object
library(lubridate)
data.tmp <- data.frame("date"= data2025$date, "value"= data2025$no2,
"year"= year(data2025$date), "month" = month(data2025$date), "week" = isoweek(data2025$date), "day"= day(data2025$date))
# compute daily maximum of hourly measurements
library(tidyr)
library(dplyr)
daily_maxima <-data.tmp %>%
group_by(year, month, week, day) %>%
slice_max(order_by = value, n = 1, with_ties = FALSE) %>%
drop_na() #drop missing observations
# Compute monthly maximum of hourly measurements
library(dplyr)
monthly_maxima <-data.tmp %>%
group_by(year, month) %>%
slice_max(order_by = value, n = 1, with_ties = FALSE) %>%
drop_na() #drop missing observations
# Compute weekly maximum of hourly measurements
library(dplyr)
weekly_maxima <-data.tmp %>%
group_by(year, month, week) %>%
slice_max(order_by = value, n = 1, with_ties = FALSE) %>%
drop_na() #drop missing observations
# Compute yearly maximum of hourly measurements
library(dplyr)
yearly_maxima <-data.tmp %>%
group_by(year) %>%
slice_max(order_by = value, n = 1, with_ties = FALSE) %>%
drop_na() #drop missing observations
# Fitting standard three-parameter GEV to annual maxima
value_year<-yearly_maxima$value
fit_year<-fgev(value_year)
fit_year1<-fgev(value_year, prob=1/10)
fit_year2<-fgev(value_year, prob=1/100)
fit_year
fit_year1
fit_year2
par(mfrow=c(1,4))
plot(fit_year)
library(ggplot2)
par(mfrow=c(1,4))
plot(fit_year)
par(mfrow=c(1,4))
plot(fit_year)
par(mfrow=c(1,4))
plot(fit_year)
# Loading data
data2025<-Sheffield.Tinsley
# See structure of the object
head(data2025)
# Creation of a data-frame object
library(lubridate)
data.tmp <- data.frame("date"= data2025$date, "value"= data2025$no2,
"year"= year(data2025$date), "month" = month(data2025$date), "week" = isoweek(data2025$date), "day"= day(data2025$date))
# compute daily maximum of hourly measurements
library(tidyr)
library(dplyr)
daily_maxima <-data.tmp %>%
group_by(year, month, week, day) %>%
slice_max(order_by = value, n = 1, with_ties = FALSE) %>%
drop_na() #drop missing observations
# Compute monthly maximum of hourly measurements
library(dplyr)
monthly_maxima <-data.tmp %>%
group_by(year, month) %>%
slice_max(order_by = value, n = 1, with_ties = FALSE) %>%
drop_na() #drop missing observations
# Compute weekly maximum of hourly measurements
library(dplyr)
weekly_maxima <-data.tmp %>%
group_by(year, month, week) %>%
slice_max(order_by = value, n = 1, with_ties = FALSE) %>%
drop_na() #drop missing observations
# Compute yearly maximum of hourly measurements
library(dplyr)
yearly_maxima <-data.tmp %>%
group_by(year) %>%
slice_max(order_by = value, n = 1, with_ties = FALSE) %>%
drop_na() #drop missing observations
# Fitting standard three-parameter GEV to annual maxima
value_year<-yearly_maxima$value
fit_year<-fgev(value_year)
fit_year1<-fgev(value_year, prob=1/10)
fit_year2<-fgev(value_year, prob=1/100)
fit_year
fit_year1
fit_year2
par(mfrow=c(1,4))
plot(fit_year)
fit_year
plot(fit_year)
par(mfrow=c(1,1))
plot(fit_year)
# Fitting standard three-parameter GEV to annual maxima
value_year<-yearly_maxima$value
fit_year<-fgev(value_year)
plot(fit_year)
par(mfrow=c(1,4))
plot(fit_year)
(plot(fit_year))
plot(fit_year, which=c(1,2))
?fgev
# Fitting standard three-parameter GEV to annual maxima
value_year<-yearly_maxima$value
fit_year<-evd::fgev(value_year)
plot(fit_year, which=c(1,2))
evd::plot(fit_year, which=c(1,2))
fit_year
plot(fit_year1)
dev.off()
dev.new()
par(mfrow=c(1,4))
plot(fit_year)
plot(c(1,2))
plot(fit_year)
print(plot(fit_year))
